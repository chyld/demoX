This module was principally about investigation into your data.  We refer to that investigative process as exploratory data analysis, or EDA, and as we have seen with the case of handling missing values there is not always a clear distinction between data ingestion and EDA. 

It is easy to see why classical methods from inferential statistics, such as hypothesis testing, naturally lend themselves to the EDA portion of the workflow.  They can be used to guide the overall investigation into the data and business opportunity.

A major advantage to inferential statistics in this context is the ability to turn a question about the business scenario into a probability.  Probabilities are the currency of inferential statistics and their utility as a tool to identify patterns and answer questions is unrivaled.  The ubiquitous p-value is a specific example of a probability that is widely used, but it too can be prone to misapplication.  Keep in mind the discussions on "p-value hacking" and multiple comparisons as you employ p-values in your work.

In this case study you will perform some simple EDA.  Then you will again put on your investigative mindset.  As a data scientist we can always become more proficient at investigative visualization.  You will investigate the 2018 world cup dataset.  There is one simple question to guide your analysis.  Was the tournament setup in a fair way?  There are 32 teams, each representing a single country and they compete in groups or pools.  In a business scenario you could look at this as an optimization problem.  If you were a company that was involved in production at different sites you would want to equally balance the teams to drive overall efficiency.  This type of analysis could be used to validate the optimization algorithms or scheme that the company used.  You will be guided to use simple hypothesis tests and control for multiple comparisons, but more sophisticated tools like multilevel modeling will be discussed.
