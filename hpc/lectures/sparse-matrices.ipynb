{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/galvanize-logo.png\" alt=\"galvanize-logo\" align=\"center\" style=\"width: 200px;\"/>\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Big Data: Sparse matrices as a tool efficient data pipeline development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Review the concept of data staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Explain when to use sparse matrices during the machine learning model development process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Describe simple uses of sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Execute Python code to work with simple sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Read the objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data staging and data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**An example natural language processing pipeline might look like this:**\n",
    "    \n",
    "    1. Gather data from multiple sources and merge into a single coprus\n",
    "    2. Represent the words themselves as tokens (numerically encoded)\n",
    "    3. Modify the the original token matrix (n-grams, remove stop words)\n",
    "    4. Carry out a transform of the token matrix like TFIDF or use Word Embeddings\n",
    "    5. Use a machine learning model on the new matrix\n",
    "    6. ...\n",
    "    \n",
    "> A staging area, or landing zone, is an intermediate storage area used for data processing during the extract, transform and load (ETL) process.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The point of showing this process is that it exemplifies that there is procedure for going from raw data to being ready to run the model.  With a large corpus it might take several minutes to perform steps 1-4.  It might take several hours under certain circumstances.  If we are trying to tune a model it makes sense to 'stage' our data after step 4.  If we are trying to compare some different transforms it makes sense to stage our data at the end of step 3.\n",
    "\n",
    "As a rule of thumb if it takes more than a few seconds to process data you should consider staging the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First steps in organizing a data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* When a machine learning model has been deployed the data ingestion pipeline for that model will also be deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* That pipeline cannot be finalized during the development of the machine learning model it feeds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Be careful about investing large amounts of time building data ingestion pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Once a well-trained machine learning model has been deployed, the data ingestion pipeline for that model will also be deployed.  That pipeline will consist of a collection of tools and systems used to fetch, transform, and feed data to the machine learning system in production.  \n",
    "\n",
    "However, that pipeline cannot be finalized during the development of the machine learning model it feeds.  \n",
    "Finalizing the process of data ingestion *before* models have been run and your hypotheses about the business use case have been tested often leads to lots of re-work. Early experiments almost always fail and you should be careful about investing large amounts of time in building a data ingestion pipeline until there is enough accumulated evidence that a deployed model will help the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse Matrices\n",
    "\n",
    "\n",
    "* Data scientists will often use *sparse matrices* during the development and testing of a machine learning model.\n",
    "\n",
    "* Python libraries available in **SciPy** package to work with sparse matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Instead of building a complete data ingestion pipeline, data scientists will often use sparse matrices during the development and testing of a machine learning model.  Sparse matrices are used to represent complex sets of data (e.g., word counts) in a way that reduces the use of computer memory and processing time. \n",
    "\n",
    "There are Python libraries available in the **SciPy** package to work with sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The code block below imports this library as well as NumPy for calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The code block below imports the SciPy library as well as the NumPy library for calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A middle-ground solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sparse matrices offer a middle-ground between:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - a comprehensive data warehouse solution with extensive test coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - a directory of text files and database dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Sparse matrices offer a middle-ground between a comprehensive data warehouse solution with extensive test coverage and a directory of text files and database dumps.  Sparse matrices do not work for all data types, but in situations where they are an appropriate technology you can leverage them even under load in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A sparse matrix is one in which most of the values are *zero*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If the number of zero-valued elements divided by the size of the matrix is greater than 0.5 then it is considered *sparse*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A sparse matrix is one in which most of the values are zero.  If the number of zero-valued elements divided by the size of the matrix is greater than 0.5 then it is consider *sparse*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;47m\n",
      "0.5017\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(0,2,100000).reshape(100,1000)\n",
    "sparsity = 1.0 - (np.count_nonzero(A) / A.size)\n",
    "print(\"\\033[1;30;47m\") # escape codes to print black font on white bg\n",
    "print(round(sparsity,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Generate an array of 100,000 random integers between 0 and 2, then reshape that array into a 100x1000 matrix, then compute the sparsity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advantage of sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Very large non-sparse matrices require significant amounts of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Sparse matrices allow you to manage large amounts of data in a memory-efficient and time-efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Very large matrices require significant amounts of memory.  For example, If we make a matrix of counts for a document or a book where the features are all known English words, the chances are high that your personal machine does not have enough memory to represent it as a dense matrix.  Sparse matrices  have the additional advantage of getting around time-complexity issues that arise with operations on large dense matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse matrices in Python\n",
    "\n",
    "**coo_matrix**: sparse matrix built from the COOrdinates and values of the non-zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A <class 'numpy.ndarray'> (10, 100) \n",
      "B <class 'scipy.sparse.coo.coo_matrix'> (10, 100) \n",
      "C <class 'numpy.matrix'> (10, 100) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.random.poisson(0.3, (10,100))\n",
    "B = sparse.coo_matrix(A)\n",
    "C = B.todense()\n",
    "\n",
    "print(\"A\",type(A),A.shape,\"\\n\"\n",
    "      \"B\",type(B),B.shape,\"\\n\"\n",
    "      \"C\",type(C),C.shape,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Create a 10x100 array of random numbers drawn from a Poisson distribution.  Then cast that sparse matrix into a matrix in coordinate format, then smash it down into a dense matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**csc_matrix**:  When there are repeated entries in the rows or cols, we can remove the redundancy by indicating the location of the first occurrence of a value and its increment instead of the full coordinates. When the repeats occur in columns we use a CSC format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (3, 2)\t1\n",
      "  (8, 2)\t1\n",
      "  (9, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (4, 4)\t2\n",
      "  (7, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 5)\t2\n",
      "  (4, 5)\t2\n",
      "  (7, 5)\t1\n",
      "  (9, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (4, 6)\t1\n",
      "  (5, 6)\t1\n",
      "  (9, 6)\t1\n",
      "  (8, 7)\t1\n",
      "  (4, 8)\t2\n",
      "  (6, 8)\t1\n",
      "  (8, 8)\t2\n",
      "  :\t:\n",
      "  (0, 87)\t1\n",
      "  (9, 87)\t1\n",
      "  (1, 88)\t1\n",
      "  (3, 88)\t1\n",
      "  (5, 88)\t1\n",
      "  (4, 89)\t1\n",
      "  (5, 89)\t1\n",
      "  (7, 90)\t2\n",
      "  (1, 91)\t1\n",
      "  (2, 91)\t1\n",
      "  (2, 92)\t1\n",
      "  (3, 92)\t1\n",
      "  (5, 92)\t1\n",
      "  (9, 92)\t1\n",
      "  (5, 93)\t1\n",
      "  (6, 93)\t1\n",
      "  (9, 94)\t1\n",
      "  (0, 95)\t1\n",
      "  (8, 95)\t1\n",
      "  (9, 95)\t1\n",
      "  (0, 96)\t2\n",
      "  (1, 96)\t1\n",
      "  (1, 97)\t2\n",
      "  (6, 98)\t1\n",
      "  (7, 98)\t2\n"
     ]
    }
   ],
   "source": [
    "A = np.random.poisson(0.3, (10,100))\n",
    "B = sparse.csc_matrix(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because the coordinate format is easier to create, it is common to create it first then cast to another more efficient format.  Let us first show how to create a matrix from coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "rows = [0,1,2,8]\n",
    "cols = [1,0,4,8]\n",
    "vals = [1,2,1,4]\n",
    "\n",
    "A = sparse.coo_matrix((vals, (rows, cols)))\n",
    "print(A.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then to cast it to a CSR matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (1, 0)\t2\n",
      "  (2, 4)\t1\n",
      "  (8, 8)\t4\n"
     ]
    }
   ],
   "source": [
    "B = A.tocsr()\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because this introduction to sparse matrices is applied to data ingestion we would need to be able to:\n",
    "\n",
    "   1. concatenate matrices (e.g., add a new user to a recommender matrix)\n",
    "   2. read and write the matrices to and from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9) (1, 9)\n",
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4]\n",
      " [0 1 0 0 2 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "## concatenate example\t\t\n",
    "C = sparse.csr_matrix(np.array([0,1,0,0,2,0,0,0,1]).reshape(1,9))\n",
    "print(B.shape,C.shape)\n",
    "D = sparse.vstack([B,C])\n",
    "print(D.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n"
     ]
    }
   ],
   "source": [
    "## read and write\n",
    "file_name = \"sparse_matrix.npz\"\n",
    "sparse.save_npz(file_name, D)\n",
    "E = sparse.load_npz(file_name)\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Questions slide"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "theme": "night"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
