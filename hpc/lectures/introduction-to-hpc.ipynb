{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/galvanize-logo.png\" alt=\"galvanize-logo\" align=\"center\" style=\"width: 200px;\"/>\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Introduction to High-Performance Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Describe the right sequence to creating programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Explain how to optimize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Describe commonly used techniques and tools for code optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* Explain why run code in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Describe what is High Performance Computing (HPC), in particular paralell computing. Explain when you need HPC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The right sequence to creating programs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Make it work\n",
    "\n",
    "2. Ensure it is right\n",
    "\n",
    "3. Make it fast i.e. code optimization + parallel computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Concentrating on the last step before the previous two can result in significantly more total work. Sometimes our programs are fast enough and we do not even need the last step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to optimize your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. To identify which part of you code need to be optimized. This is done using\n",
    "[profiling](https://en.wikipedia.org/wiki/Profiling_(computer_programming)) or more specifically [Python\n",
    "profilers](https://docs.python.org/3/library/profile.html). \n",
    "\n",
    "2. look around for implementations before you build your own.\n",
    "\n",
    ">- For generic optimization: [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html)\n",
    "\n",
    ">- For graph related problem: [algorithms implemented by NetworkX](https://networkx.github.io/documentation/stable/reference/algorithms/index.html)\n",
    "    \n",
    "3. When there is no existing implementation, consider optimizing code by some common tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Commonly used techniques and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Use appropriate data containers\n",
    "    For example, a Python set has a shorter look-up time than a Python list.  Similarly, use dictionaries and NumPy\n",
    "    arrays whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Multiprocessing](https://docs.python.org/3/library/multiprocessing.html)\n",
    "    This is a package in the standard Python library and it supports spawning processes (for each core) using an API\n",
    "    similar to the threading module. The multiprocessing package offers both local and remote concurrency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Threading](https://docs.python.org/3/library/threading.html#module-threading)\n",
    "    Another package in the standard library that allows separate flows of execution at a lower level than\n",
    "    multiprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Subprocessing](https://docs.python.org/3/library/subprocess.html)\n",
    "    A module that allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.\n",
    "    You may run **and control** non-Python processes like Bash or R with the subprocessing module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Multiprocessing](https://docs.python.org/3/library/multiprocessing.html)\n",
    "    This is a package in the standard Python library and it supports spawning processes (for each core) using an API\n",
    "    similar to the threading module. The multiprocessing package offers both local and remote concurrency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [mpi4py](https://mpi4py.readthedocs.io/en/stable/)\n",
    "    MPI for Python provides bindings of the Message Passing Interface (MPI) standard for the Python programming\n",
    "    language, allowing any Python program to exploit multiple processors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [ipyparallel](https://ipyparallel.readthedocs.io/en/latest/)\n",
    "    Parallel computing tools for use with Jupyter notebooks and IPython.  Can be used with mpi4py.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Cython](https://cython.org/)\n",
    "     An optimizing static compiler for both the Python programming language and the extended Cython programming language\n",
    "     It is generally used to write C extensions for slow portions of code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [CUDA(Compute Unified Device Architecture)](https://en.wikipedia.org/wiki/CUDA)\n",
    "    Parallel computing platform and API created by [Nvidia](https://www.nvidia.com/en-us/) for use with CUDA-enabled\n",
    "    GPUs.  CUDA in the Python environment is often  run using the package [PyCUDA](https://documen.tician.de/pycuda/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why run code in parallel?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * Modern computers have multiple cores and [hyperthreading](https://en.wikipedia.org/wiki/Hyper-threading)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Graphics processing units (GPUs) have driven many of the recent advancements in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Many of the newest *i7* processors have 8 cores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * The is a lot of **potential** but the overhead can be demanding for some problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How many cores do I have?\n",
    "\n",
    "Parallel computing can help us make better use of the available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cores:  4\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "total_cores = cpu_count()\n",
    "print('total cores: ', total_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High-performance computing\n",
    "\n",
    "The aggregation of compute resources to dramatically increase available compute resources is known as high-performance computing (HPC)\n",
    "\n",
    "In particular, [parallel computing](https://en.wikipedia.org/wiki/Parallel_computing)\n",
    "is what we enable by adding multiple GPUs to compuation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two laws that constrain the maximum speed-up of computing:\n",
    "\n",
    "- [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law)\n",
    "\n",
    "- [Gustafson's law](https://en.wikipedia.org/wiki/Gustafson%27s_law)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important terminologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- [Symmetric multiprocessing](https://en.wikipedia.org/wiki/Symmetric_multiprocessing)\n",
    "    Two or more identical processors connected to a single unit of memory.\n",
    "- [Distributed computing](https://en.wikipedia.org/wiki/Distributed_computing)\n",
    "    Processing elements are connected by a network.\n",
    "- [Cluster computing](https://en.wikipedia.org/wiki/Computer_cluster)\n",
    "    Group of loosely (or tightly) coupled computers that work together in a way that they can be viewed as a single system.\n",
    "- [Massive parallel processing](https://en.wikipedia.org/wiki/Massively_parallel)\n",
    "    Many networked processors usually > 100 used to perform computations in parallel.\n",
    "- [Grid computing](https://en.wikipedia.org/wiki/Grid_computing)\n",
    "    distributed computing making use of a middle layer to create a `virtual super computer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions to ask for data science scaling\n",
    "\n",
    "**data science scaling = code optimization + parallel computing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Does my service train in a reasonable amount of time given a lot more data?\n",
    "\n",
    "* Does my service predict in a reasonable amount of time given a lot more data?\n",
    "\n",
    "* Is my service ready to support additional request load?\n",
    "\n",
    "Here, **service** = **the deployed model** + **the infrastructure**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It is important to think about what kind of scale is required by your model and business application in terms of which\n",
    "bottleneck is most likely going to be the problem associated with scale.  These bottlenecks will depend heavily on\n",
    "available infrastructure, code optimizations, choice of model and type of business opportunity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### data science scaling = code optimization + parallel computing.\n",
    "\n",
    "Example: We could use [Apache Spark](https://spark.apache.org/), a cluster-computing framework, to enable parallel computing."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "theme": "night"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}